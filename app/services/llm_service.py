"""
LLM Service - Integraci√≥n con Groq v√≠a LiteLLM

RESPONSABILIDADES:
- Preparar prompts en contexto
- Llamar Groq API
- Manejo de errores y retries
- Logging de uso

ARQUITECTURA:
- Minimal: Solo Groq por ahora
- Extensible: F√°cil agregar Claude, DeepSeek, OpenAI despu√©s
- Async-ready: Para streaming futuro
"""

import logging
from app.core.config import settings

logger = logging.getLogger(__name__)


class LLMService:
    """
    Servicio centralizado para llamadas a LLM
    
    Interfaz:
    - groq_generate(content: str, prompt: str) -> str
    """
    
    def __init__(self):
        self.api_key = settings.GROQ_API_KEY
        self.model = "llama-3.3-70b-versatile"  # Modelo activo (llama-3.1-70b fue deprecado)
        
        if not self.api_key:
            logger.warning("‚ö†Ô∏è  GROQ_API_KEY no configurada")
    
    def groq_generate(self, content: str, prompt: str, context_hierarchy: str = None) -> str:
        """
        Genera una respuesta usando Groq
        
        Args:
            content: Texto plano completo de la nota activa
            prompt: Pregunta del usuario
            context_hierarchy: Jerarqu√≠a de bibliotecas/cuadernos/temas/notas (JSON string)
        
        Returns:
            Respuesta de texto de Groq
        
        Raises:
            Exception: Si hay error con la API
        """
        import litellm
        
        if not self.api_key:
            raise Exception("GROQ_API_KEY no configurada")
        
        try:
            # System prompt: contexto para la IA
            system_prompt = """Eres un asistente inteligente para un sistema de notas.

Tu prop√≥sito es ayudar al usuario con preguntas sobre sus notas, su estructura y contenido.

ESTRUCTURA DE LA INFORMACI√ìN QUE RECIBES:
1. NOTA ACTIVA: La nota en la que est√°s trabajando actualmente (contenido completo)
2. JERARQU√çA: Tu biblioteca completa organizada como:
   - Bibliotecas (Categor√≠as)
     ‚îî‚îÄ Cuadernos
       ‚îî‚îÄ Temas
         ‚îî‚îÄ Notas (solo t√≠tulos, sin contenido)

INSTRUCCIONES CR√çTICAS - DETERMINA QU√â RESPONDER:

A. Si la pregunta es sobre BIBLIOTECAS, CUADERNOS, TEMAS o la ESTRUCTURA:
   ‚Üí Responde DIRECTAMENTE sobre la jerarqu√≠a
   ‚Üí Ejemplo: "cuales bibliotecas tengo?" ‚Üí Lista todas las bibliotecas de la jerarqu√≠a
   ‚Üí Ejemplo: "cuales notas tengo en X cuaderno?" ‚Üí Lista las notas en ese cuaderno
   ‚Üí NO necesitas mencionar la nota activa

B. Si la pregunta es sobre la NOTA ACTIVA:
   ‚Üí Responde enfoc√°ndote en el contenido de la nota activa
   ‚Üí Puedes sugerir notas relacionadas en la jerarqu√≠a

C. Si la pregunta es GENERAL o pide CONEXIONES:
   ‚Üí Usa ambos: nota activa como contexto + jerarqu√≠a como referencias
   ‚Üí Sugiere notas relacionadas si es relevante

FORMATO DE RESPUESTA:
- Texto plano limpio (sin markdown, sin HTML)
- Mant√©n saltos de l√≠nea naturales
- Si mencionas otras notas: "tu nota 'nombre' en Biblioteca > Cuaderno > Tema"
- S√© conciso y directo"""

            # Preparar el mensaje de usuario
            user_message = f"""JERARQU√çA DE TUS NOTAS:
{context_hierarchy or "No hay jerarqu√≠a disponible"}

"""
            
            # Agregar nota activa solo si hay contenido
            if content and content.strip():
                user_message += f"""NOTA ACTIVA (opcional, para contexto):
{content}

"""
            
            user_message += f"""PREGUNTA DEL USUARIO:
{prompt}

Responde seg√∫n las instrucciones: si es sobre estructura/bibliotecas, responde eso directamente. Si es sobre la nota activa, responde sobre ella."""

            # üîç LOG DETALLADO para debugging
            logger.info(f"\n{'='*80}")
            logger.info(f"ü§ñ GROQ REQUEST DETAILS")
            logger.info(f"{'='*80}")
            logger.info(f"\nüìã SYSTEM PROMPT:\n{system_prompt}\n")
            logger.info(f"\nüë§ USER MESSAGE:\n{user_message}\n")
            logger.info(f"{'='*80}\n")

            # Llamar a Groq v√≠a LiteLLM
            response = litellm.completion(
                model=f"groq/{self.model}",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                temperature=0.7,
                max_tokens=1024,
                api_key=self.api_key,
                timeout=30
            )
            
            # Extraer respuesta
            answer = response.choices[0].message.content
            
            logger.info(f"‚úÖ Groq response generada ({len(answer)} chars)")
            
            return answer
            
            
        except Exception as e:
            logger.error(f"‚ùå Error en Groq: {str(e)}")
            raise Exception(f"Error generando respuesta: {str(e)}")